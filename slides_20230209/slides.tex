\documentclass{beamer}

\mode<presentation> {
\usetheme{AnnArbor}
}

\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage[shortlabels]{enumitem}
\usepackage{biblatex}
\addbibresource{bibliography.bib}

\newcommand{\PRM}{\text{PRM}}
\newtheorem{proposition}{Proposition}

\title[Point Processes in Extreme Value Theory]{Point Processes in Extreme Value Theory}

\author{Victor Verma}
\institute[]
{
Prof. Yang Chen's Reading Group \\
Department of Statistics \\
University of Michigan
}
\date[2/9/23]{2/9/23} 

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}{Today's Reading}
    \begin{itemize}
        \item Chapter 5 of \textit{Modelling Extremal Events} by Embrechts, Kl\"{u}ppelberg, and Mikosch (\cite{embrechts_et_al_1997})
    \end{itemize}
\end{frame}

%\begin{frame}{Outline}
%    \tableofcontents
%\end{frame}

%\begin{frame}{An Example Problem}
%\end{frame}

\begin{frame}{What is a Point Process?}
    A \textbf{point process} models a random configuration of points in a space $E$.

    \smallskip

    $E$ is assumed to be a topological space that
    \begin{itemize}
        \item is Hausdorff
        \item is locally compact
        \item has a countable basis
    \end{itemize}
    For simplicity, we can assume that $E$ is a subset of a finite-dimensional Euclidean space $\mathbb{R}^d$.

    \smallskip
    
    Let $\mathcal{E}$ be the Borel $\sigma$-algebra on $E$, i.e., the $\sigma$-algebra generated by the open subsets of $E$.
\end{frame}

\begin{frame}{What is a Point Process?}
    For $x \in E$, the \textbf{Dirac measure} $\epsilon_x : \mathcal{E} \to [0, \infty]$ is defined by
    \[
    \epsilon_x(A) =
        \begin{cases}
             1 & \text{if $x \in A$} \\
             0 & \text{if $x \notin A$}
        \end{cases}
    \]

    \smallskip

    Let $\{x_i\}_{i = 1}^{\infty}$ be a sequence in $E$. Define $m : \mathcal{E} \to [0, \infty]$ by
    \[
    m(A) = \sum_{i = 1}^{\infty} \epsilon_{x_i}(A)
    \]
    and assume that $m$ is \textbf{Radon}, i.e., $m(K) < \infty$ for all compact $K \subseteq E$. $m$ is called a \textbf{point measure}.

    \smallskip

    For $E \subseteq \mathbb{R}^d$, the Radon condition is equivalent to the condition that any bounded $A \subseteq E$ contains finitely many $x_i$'s.
\end{frame}

\begin{frame}{What is a Point Process?}
    Let $M_p(E)$ be the set of all point measures on $E$. Let $\mathcal{M}_p(E)$ be the $\sigma$-algebra generated by sets of the form
    \[
    \{m \in M_p(E) : m(A) \in B\},
    \]
    where $A \in \mathcal{E}$ and $B \in \mathcal{B}([0, \infty])$.

    \smallskip

    \begin{definition}
        A \textbf{point process} on $E$ is a measurable map
        \[
        N : (\Omega, \mathcal{F}, P) \to (M_p(E), \mathcal{M}_p(E)),
        \]
        where $(\Omega, \mathcal{F}, P)$ is a probability space.
    \end{definition}
\end{frame}

\begin{frame}{Simplicity}
    \begin{itemize}
        \item A point measure $m = \sum_{i = 1}^{\infty} \epsilon_{x_i}$ is \textbf{simple} if the $x_i$'s are distinct.
        \item A point process $N$ is \textbf{simple} if $N(\omega)$ is a simple point measure for all $\omega \in \Omega$.
    \end{itemize}
\end{frame}

\begin{frame}{More about $\mathcal{M}_p(E)$}
    $\mathcal{M}_p(E)$ is the smallest $\sigma$-algebra that makes $m \mapsto m(A)$ measurable for all $A \in \mathcal{E}$. Because of this, $N$ is a point process if and only if $N(A)$ is an extended real-valued random variable for all $A \in \mathcal{E}$. More formally,
    \begin{proposition}
    $N : \Omega \to M_p(E)$ is a point process if and only if for all $A \in \mathcal{E}$, $\omega \mapsto N(\omega, A)$ is a measurable mapping from $(\Omega, \mathcal{F})$ to $([0, \infty], \mathcal{B}[0, \infty])$.
    \end{proposition}
\end{frame}

\begin{frame}{A General Way to Create Point Processes}
    Let $\{X_i\}_{i = 1}^{\infty}$ be a sequence of random elements of $E$. Let
    \[
    N = \sum_{i = 1}^{\infty} \epsilon_{X_i}.
    \]
    If $\sum_{i = 1}^{\infty} \epsilon_{X_i(\omega)}$ is Radon for all $\omega$, then $N$ is a point process.
\end{frame}

\begin{frame}{Renewal Counting Processes}
    Let $\{Y_i\}_{i = 1}^{\infty}$ be a sequence of iid positive random variables. Let $T_n = Y_1 + \ldots + Y_n$. Define $\tilde{N}(t)$ by
    \[
    \tilde{N}(t) = \#\{i : T_i \le t\}, \quad t \ge 0.
    \]
    $\tilde{N}(t)$ is called a \textbf{renewal counting process}.

    \smallskip
    
    Let $E = [0, \infty)$ and define $N(A)$ by
    \[
    N(A) = \sum_{i = 1}^{\infty} \epsilon_{T_i}(A), \quad A \in \mathcal{E}.
    \]
    Note that $\tilde{N}(t) = N([0, t])$.

    \smallskip

    Let the $Y_i$'s be iid exponential with common mean $1 / \lambda$ for some $\lambda > 0$. Then $\tilde{N}$ is a homogeneous Poisson process with intensity $\lambda$, and $N$ is simple.
\end{frame}

\begin{frame}{The Point Process of Exceedances}
    Let $\{X_n\}_{n = 1}^{\infty}$ be a sequence of random variables defined on $(\Omega, \mathcal{F}, P)$ and let $u \in \mathbb{R}$. Let $E = (0, 1]$ and $\mathcal{E} = \mathcal{B}(E)$. For $n \in \mathbb{N}$, the \textbf{point process of exceedances} $N_n$ is defined for all $A \in \mathcal{E}$ by
    \[
    N_n(A) = \sum_{i = 1}^n \epsilon_{i / n}(A)I_{\{X_i > u\}}.
    \]
    We have $N_n(E) = \sum_{i = 1}^n \epsilon_{i / n}(E)I_{\{X_i > u\}} = \sum_{i = 1}^n I_{\{X_i > u\}}$, i.e., how many of $X_1, \ldots, X_n$ exceed $u$.
\end{frame}

\begin{frame}{The Point Process of Exceedances}
    Let $X_{1, n} \ge \ldots \ge X_{n, n}$ be the order statistics of $X_1, \ldots, X_n$. We have
    \begin{align*}
        N_n(E) = 0 &\iff X_{1, n} \le u \\
        N_n(E) < k &\iff X_{k, n} \le u
    \end{align*}
    for any $k$.

    \smallskip

    We can write
    \[
    \tilde{N}_n(\cdot) = \sum_{i = 1}^n \epsilon_{i / n, X_i}(\cdot),
    \]
    which has two-dimensional state space $E = (0, 1] \times (u, \infty)$. Then
    \[
    \tilde{N}_n(A \times (u, \infty)) = N_n(A).
    \]
\end{frame}

\begin{frame}{Distributions and Mean Measures}
    The \textbf{distribution} $P_N$ of a point process $N$ is the probability measure $P \circ N^{-1} = P(N \in \cdot)$ defined on $\mathcal{M}_p(E)$.

    \smallskip

    The \textbf{mean measure} $\mu$ of a point process $N$ satisfies
    \begin{align*}
        \mu(A) &= E[N(A)] \\
        &= \int_{\Omega} (N(\omega))(A)\,dP(\omega) \\
        &= \int_{M_p(E)} m(A)\,d(P \circ N^{-1})(m) \\
        &= \int_{M_p(E)} m(A)\,dP_N(m).
    \end{align*}
\end{frame}

\begin{frame}{Laplace Functionals}
    For a measure $m$, write $\int_E g\,dm$ as $m(g)$. The \textbf{Laplace functional} $\Psi_N$ of a point process $N$ is defined by
    \begin{align*}
        \Psi_N(g) &= E[e^{-N(g)}] \\
        &= \int_{\Omega} e^{-N(\omega)(g)}\,dP(\omega) \\
        &= \int_{M_p(E)} e^{-m(g)}\,dP_N(m)
    \end{align*}
    for nonnegative measurable functions $g$ on $E$.
\end{frame}

\begin{frame}{Laplace Functionals}
    The \textbf{finite-dimensional distributions} of a point process $N$ are the distributions of the random vectors of the form $(N(A_1), \ldots, N(A_m))$, $m \ge 1$, $A_1, \ldots, A_m \in \mathcal{E}$.
    \begin{proposition}
        The finite-dimensional distributions of a point process $N$ uniquely determine its distribution $P_N$.
    \end{proposition}
    \begin{proposition}
        The Laplace functional $\Psi_N$ of a point process $N$ uniquely determines its distribution $P_N$.
    \end{proposition}
\end{frame}

\begin{frame}{Poisson Random Measures}
    Let $M_+(E)$ be the set of nonnegative Radon measures on $E$. A point process $N$ is a \textbf{Poisson random measure (PRM)} or \textbf{Poisson process} with \textbf{mean measure} $\mu \in M_+(E)$ if
    \begin{itemize}
    \item for all $A \in \mathcal{E}$, for all $k \ge 0$,
    \[
    P(N(A) = k) =
        \begin{cases}
            e^{-\mu(A)}\frac{(\mu(A))^k}{k!} & \text{if $\mu(A) < \infty$} \\
            0 & \text{if $\mu(A) = \infty$}
        \end{cases}
    \]
    \item For all $m \ge 1$, for all disjoint $A_1, \ldots, A_m \in \mathcal{E}$, $N(A_1), \ldots, N(A_m)$ are independent.
    \end{itemize}
    An arbitrary PRM with mean measure $\mu$ is denoted $\PRM(\mu)$.
\end{frame}

\begin{frame}{The Laplace Functional of a PRM}
    \begin{proposition}
        If $N$ is $\PRM(\mu)$, then for all nonnegative measurable functions $g$ on $E$,
        \[
        \Psi_N(g) = \exp\left\{-\int_E \left(1 - e^{-g(x)}\right)\,d\mu(x)\right\} \tag{$\star$}
        \]
        Conversely, if there exists $\mu \in M_+(E)$ such that ($\star$) holds, then $N$ is $\PRM(\mu)$.
    \end{proposition}
\end{frame}

\begin{frame}{Homogeneous PRMs}
    Let $N$ be $\PRM(\mu)$, and suppose that $\mu$ is absolutely continuous with respect to Lebesgue measure. By the Radon-Nikodym Theorem, for some nonnegative measurable function $f$ on $E$, for all $A \in \mathcal{E}$,
    \[
    \mu(A) = \int_A f(x)\,dx;
    \]
    $f$ is called the \textbf{intensity} of $N$.

    \smallskip
    
    Let $N$ be $\PRM(\lambda|\cdot|)$, where $\lambda > 0$ and $|\cdot|$ represents Lebesgue measure on $E$. Then $N$ is called a \textbf{homogeneous} PRM; its intensity is $\lambda$.
\end{frame}

\begin{frame}{Weak Convergence of Point Processes}
    Let $N, N_1, N_2, \ldots$ be point processes on $E$. The sequence $\{N_n\}_{n = 1}^{\infty}$ \textbf{converges weakly} to $N$ in $M_p(E)$ (written $N_n \xrightarrow{d} N$) if for all $m \ge 1$, for all $A_1, \ldots, A_m \in \mathcal{E}$,
    \[
    \lim_{n \to \infty} P(N_n(A_1), \ldots, N_n(A_m)) = P(N(A_1), \ldots, N(A_m)).
    \]
\end{frame}

\begin{frame}{Weak Convergence of Point Processes}
    \begin{proposition}
        Let $\{N_n\}_{n = 1}^{\infty}$ and $N$ be point processes on $E = (a, b] \subset \mathbb{R}$ and let $N$ be simple. Suppose the following two conditions hold:
        \begin{itemize}
            \item $E[N_n(A)] \to E[N(A)]$ for all $A = (c, d] \subset (a, b]$
            \item $P(N_n(B) = 0) \to P(N(B) = 0)$ for all $B = \bigcup_{i = 1}^k (c_i, d_i]$, for all $k \ge 1$, where $a < c_1 < d_1 < \cdots < c_k < d_k \le b$.
        \end{itemize}
        Then $N_n \xrightarrow{d} N$ in $M_p(E)$.
    \end{proposition}
\end{frame}

\begin{frame}{Weak Convergence of Point Processes}
    Let $C_K^+(E)$ be the set of all nonnegative, continuous functions on $E$ that have compact support. Weak convergence of point processes can be determined using their Laplace functionals:
    \begin{proposition}
        The point processes $\{N_n\}_{n = 1}^{\infty}$ converge weakly to the point process $N$ in $M_p(E)$ if and only if the corresponding Laplace functionals converge for every $g \in C_K^+(E)$ as $n \to \infty$, i.e.,
        \[
        \lim_{n \to \infty} \Psi_{N_n}(g) = \Psi_N(g).
        \]
    \end{proposition}
\end{frame}

\begin{frame}{The Point Process of Exceedances for IID Sequences}
    Let $\bar{F}$ be the tail of the distribution function $F$ and $M_n = X_{1, n} = \vee_{i = 1}^n X_i$.
    \begin{proposition}
        For given $\tau \in [0, \infty]$ and a sequence $\{u_n\}$ of real numbers the following are equivalent:
        \begin{align*}
            n\bar{F}(u_n) &\to \tau \\
            P(M_n \le u_n) &\to e^{-\tau}.
        \end{align*}
        Alternatively, the following are equivalent:
        \begin{align*}
            E\left[\sum_{i = 1}^n I_{\{X_i > u_n\}}\right] &\to \tau \\
            P(X_{1, n} \le u_n) &\to e^{-\tau}.
        \end{align*}
    \end{proposition}
\end{frame}

\begin{frame}{The Point Process of Exceedances for IID Sequences}
    \begin{proposition}
        Let $\{X_n\}_{n = 1}^{\infty}$ be a sequence of iid random variables with common distribution function $F$. Let $\{u_n\}_{n = 1}^{\infty}$ be threshold values such that $n\bar{F}(u_n) \to \tau \in (0, \infty)$. Then the point processes of exceedances $N_n(\cdot) = \sum_{i = 1}^n \epsilon_{i / n}(\cdot)I_{\{X_i > u_n\}}$ converge weakly in $M_p(E)$ to a homogeneous Poisson process $N$ on $E = (0, 1]$ with intensity $\tau$, i.e., $N$ is $\PRM(\tau|\cdot|)$.
    \end{proposition}

    Thus,
    \begin{align*}
        P(X_{k, n} \le u_n) &= P(N_n((0, 1]) < k) \\
        &\approx P(N((0, 1]) < k) \\
        &\approx e^{-\tau}\sum_{i = 0}^{k - 1} \frac{\tau^i}{i!}.
    \end{align*}
\end{frame}

\begin{frame}{Records and Record Times}
    Let $\{X_n\}_{n = 1}^{\infty}$ be a sequence of iid random variables with common continuous distribution function $F$. Let $x_F^{\ell} = \sup\{x : F(x) = 0\}$ and $x_F^r = \inf\{x : F(x) = 1\}$ be the left and right endpoints of $F$, respectively. Let $M_n = \vee_{i = 1}^n X_i$.

    \smallskip

    $X_n$ is a \textbf{record} if $X_n = M_n$. $L_n$ is a \textbf{record time} if $X_{L_n}$ is a record.
\end{frame}

\begin{frame}{A Point Process Description of Records}
    \begin{proposition}
        Let $F$ be a continuous distribution function with left endpoint $x_F^{\ell}$ and right endpoint $x_F^r$. Then the records $\{X_{L_n}\}_{n = 1}^{\infty}$ of the iid sequence $\{X_n\}_{n = 1}^{\infty}$ are the points of a $\PRM(\mu)$ on $(x_F^{\ell}, x_F^r)$ with mean measure $\mu$ given by
        \[
        \mu((a, b]) = R(b) - R(a), \quad x_F^{\ell} < a < b \le b < x_F^r,
        \]
        where $R(x) = -\log\bar{F}(x)$. In particular, if $F$ is standard exponential then $R(t) = t$ and $\{X_{L_n}\}_{n = 1}^{\infty} \overset{d}{=} \{\Gamma_n\}_{n = 1}^{\infty}$ are the points of a homogeneous Poisson process on $\mathbb{R}_+$ with intensity 1.
    \end{proposition}
\end{frame}

\begin{frame}{$F$-Extremal Processes}
    For $m \ge 1$, for positive integers $t_1 < \cdots < t_m$, for $x_1, \ldots, x_m \in \mathbb{R}$, we can show that the finite-dimensional distributions of $\{M_n\}_{n = 1}^{\infty}$ have the form
    \[
    P(M_{t_1} \le x_1, \ldots, M_{t_m} \le x_m) = F^{t_1}\left(\bigwedge_{i = 1}^m x_i\right)F^{t_2 - t_1}\left(\bigwedge_{i = 2}^m x_i\right) \cdots F^{t_m - t_{m - 1}}\left(x_m\right).
    \]
    The associated \textbf{$F$-extremal process} $\{Y(t)\}_{t > 0}$ has finite-dimensional distributions of the same form, except $t_1, \ldots, t_m$ can be real. Thus,
    \[
    \{M_n\}_{n = 1}^{\infty} \overset{d}{=} \{Y(n)\}_{n = 1}^{\infty}.
    \]
\end{frame}

\begin{frame}{$F$-Extremal Processes}
    Let
    \[
    N = \sum_{k = 1}^{\infty} \epsilon_{(t_k,\,j_k)}
    \]
    be $\PRM(|\cdot| \times \mu)$ with state space $E = \mathbb{R}_+ \times \mathbb{R}$, where $|\cdot|$ denotes Lebesgue measure and $\mu$ satisfies $\mu((a, b]) = \log F(b) - \log F(a)$ for $a < b$. We can use $N$ to derive a representation for $Y$:
    % Proposition 5.4.4
    \begin{proposition}
        The $F$-extremal process $Y = \{Y(t)\}_{t > 0}$ has representation
        \[
        Y(t) \overset{d}{=} \sup\{j_k : t_k \le t\}.
        \]
    \end{proposition}
\end{frame}

\begin{frame}{$F$-Extremal Processes}
    Let $\tau_1, \tau_2, \ldots$ represent the jump times of an $F$-extremal process $Y$. The point process $N_{\infty}$ of these jump times has a simple representation:
    % Theorem 5.4.7
    \begin{proposition}
        If $F$ is continuous, then
        \[
        N_{\infty} = \sum_{n = 1}^{\infty} \epsilon_{\tau_n}
        \]
        is $\PRM(\mu)$ on $\mathbb{R}_+$ with intensity $f(t) = 1 / t$, i.e.,
        \[
        \mu((a, b]) = \int_a^b f(t)\,dt = \log b - \log a \quad \text{for $a < b$}
        \]
    \end{proposition}
\end{frame}

\begin{frame}{Coupling}
    The point process $N$ of the record times $\{L_n\}_{n = 1}^{\infty}$ is defined as
    \[
    N = \sum_{i = 1}^{\infty} \epsilon_{L_i}.
    \]
    We have
    \begin{align*}
        N((n - 1, n]) = 1 &\iff \text{$\{X_i\}_{i = 1}^{\infty}$ has a record at time $n$} \\
        &\iff N_{\infty}((n - 1, n]) \ge 1.
    \end{align*}
    A natural question: when is $N_{\infty}((n - 1, n]) > 1$?
\end{frame}

\begin{frame}{Coupling}
    % Proposition 5.4.8 in Embrechts et al.
    \begin{proposition}
        Assume the distribution function $F$ is continuous and that $\{L_n\}_{n = 1}^{\infty}$ and $\{\tau_n\}_{n = 1}^{\infty}$ are constructed as above. Then there exists an integer-valued random variable $N_0$ such that for almost every $\omega \in \Omega$,
        \[
        N((n, n + 1], \omega) = N_{\infty}((n, n + 1], \omega), \quad n \ge N_0(\omega). \tag{$\star$}
        \]
        Alternatively, for almost every $\omega \in \Omega$, there exists an integer $j(\omega)$ such that
        \[
        N_{\infty}((1, n], \omega) = j(\omega) + N((1, n], \omega), \quad n \ge N_0(\omega). \tag{$\star\star$}
        \]
    \end{proposition}
    ($\star$) and ($\star\star$) are formulations of the \textbf{coupling relation}.
\end{frame}

\begin{frame}{The Frequency of Records}
    % Theorem 5.4.9 in Embrechts et al.
    \begin{proposition}
        The limit relation
        \[
        N_n(\cdot) = N(n\cdot) = \sum_{i = 1}^{\infty} \epsilon_{L_i / n}(\cdot) \xrightarrow{d} N_{\infty}(\cdot) = \sum_{i = 1}^{\infty} \epsilon_{\tau_i}(\cdot)
        \]
        holds in $M_p(\mathbb{R}_+)$.
    \end{proposition}
\end{frame}

\begin{frame}{The Frequency of Records}
    % Theorem 5.4.10 in Embrechts et al.
    \begin{proposition}
        Suppose $F$ has a continuous distribution, let $\{X_n\}_{n = 1}^{\infty}$ be an iid sequence with record times $\{L_n\}_{n = 1}^{\infty}$ and let $N$ be the corresponding point process $\sum_{i = 1}^{\infty} \epsilon_{L_i}$. Then the following relations hold:
        \begin{itemize}
            \item $\lim_{t \to \infty} (\log t)^{-1}N((1, t]) = 1$ a.s.
            \item $(\log t)^{-1 / 2}(N((1, t]) - \log t) \xrightarrow{d} \Phi$, where $\Phi$ is the standard normal distribution function
        \end{itemize}
    \end{proposition}
\end{frame}

\begin{frame}{The Growth of Record Times}
    \begin{proposition}
        Assume $F$ is continuous. Then the following relations hold for the record times $L_n$ of an iid sequence $\{X_n\}_{n = 1}^{\infty}$:
        \begin{itemize}
            \item $\lim_{n \to \infty} n^{-1}\log L_n = 1$ a.s.
            \item $n^{-1 / 2}(\log L_n - n) \xrightarrow{d} \Phi$, where $\Phi$ is the standard normal distribution function
        \end{itemize}
    \end{proposition}
\end{frame}

\section{References}

\begin{frame}[allowframebreaks]{References}
    \nocite{*}
    \printbibliography
\end{frame}

\end{document}